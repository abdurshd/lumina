# Lumina — Agentic Transformation Plan

> **Goal:** Transform Lumina from a linear user-driven assessment platform into an autonomous career intelligence agent that orchestrates multi-source analysis, adaptive assessment, live multimodal coaching, and self-correcting synthesis — to win the Gemini 3 Hackathon.

---

## Why This Plan Exists

Lumina is being submitted to the **Gemini 3 Hackathon** ($100K prize pool). The hackathon **strongly discourages**:
- Generic chatbots for personality analysis or job screening
- Prompt-only wrappers (system prompt + basic UI)
- Apps where "a single prompt can solve it"
- Simple vision analyzers (snapshot-based, not temporal)
- Baseline RAG (simple data retrieval)

Currently, Lumina falls into several of these categories:
- The report is generated by a **single Gemini call** (prompt wrapper)
- The quiz is **stateless** — previous answers are just appended to the next prompt
- The live session is a **personality analysis chatbot** with basic tool calls
- The workflow is **entirely user-driven** — no autonomous decisions
- There is **no self-correction, no confidence gating, no agent loops**

The hackathon rewards **"orchestrators building robust systems"** and highlights strategic tracks:
- **The Marathon Agent** — autonomous multi-step systems with self-correction
- **The Real-Time Teacher** — Live API for adaptive learning

This plan transforms Lumina into a genuine agentic system.

---

## Task Status Legend

| Symbol | Meaning |
|--------|---------|
| `[ ]` | Pending — not started, available to pick up |
| `[~]` | In Progress — an agent or human is actively working on this |
| `[x]` | Done — completed and verified |
| `[-]` | Blocked — waiting on a dependency |
| `[!]` | Needs Review — done but needs human verification |

## Task Lock Format

```
LOCK: UNLOCKED
```
or
```
LOCK: <agent-name> | <date> <time>
```

When picking up a task, an agent MUST:
1. Change status from `[ ]` to `[~]`
2. Set the LOCK to their name and timestamp
3. When done, change status to `[x]` or `[!]` and set LOCK back to `UNLOCKED`

If a task has been locked for >2 hours with no progress, it can be force-unlocked.

---

## Immediate Stability Fixes (Completed)

- [x] Add App Router error boundaries and custom 404 experience
  - `src/app/global-error.tsx`
  - `src/app/error.tsx`
  - `src/app/(app)/error.tsx`
  - `src/app/(auth)/error.tsx`
  - `src/app/not-found.tsx`

---

## Phase 1: Agent Infrastructure (Foundation)

> Everything else depends on this. Build the core agent orchestrator, confidence system, and decision log before touching any existing features.

---

### Task 1.1 — Agent Orchestrator Core

```
STATUS: [x]
LOCK: UNLOCKED
PRIORITY: CRITICAL
DEPENDS ON: nothing
BLOCKS: 2.1, 2.2, 3.1, 3.2, 4.1, 5.1, 6.1, 7.1, 7.2
```

**What:** Create a server-side agent orchestrator that autonomously decides what actions to take based on the current state of the user's assessment data, confidence levels, and gaps.

**Why:** Currently the user manually clicks through stages (connections → quiz → session → report). The hackathon wants "autonomous systems for tasks spanning hours" with "self-correction across multi-step tool calls." An orchestrator that evaluates state and decides next actions is the core differentiator between "prompt wrapper" and "agentic system."

**Implementation:**

Create `src/lib/agent/orchestrator.ts`:
- Define an `AgentState` type that captures: connected data sources, quiz completion per module, quiz confidence per dimension, session completion status, behavioral observations count, overall profile confidence, identified gaps
- Implement `evaluateState(state: AgentState): AgentAction[]` — a pure function that examines current state and returns prioritized list of recommended actions
- Action types: `analyze_source`, `run_quiz_module`, `start_session`, `generate_report`, `refine_report_section`, `request_additional_data`, `probe_dimension`
- Each action has: `type`, `priority`, `reason` (human-readable why), `confidence_impact` (expected improvement), `blocked_by` (dependencies)
- Implement confidence thresholds: report generation requires minimum 60% average dimension confidence; individual career matches require minimum 50% evidence strength
- The orchestrator does NOT execute actions — it recommends them. The execution happens through existing API routes.

Create `src/lib/agent/types.ts`:
- `AgentState`, `AgentAction`, `AgentDecision`, `ConfidenceProfile`, `DimensionGap`
- `AgentDecisionLog` — record of what the agent decided and why

Create API route `src/app/api/agent/evaluate/route.ts`:
- POST endpoint that takes current user state
- Calls `evaluateState()` and returns recommended actions
- Logs the decision to Firestore under `agent_decisions/{uid}`

**Files to create:**
- `src/lib/agent/orchestrator.ts`
- `src/lib/agent/types.ts`
- `src/app/api/agent/evaluate/route.ts`

**Files to modify:**
- `src/types/index.ts` — add AgentState, AgentAction, AgentDecision types

**Acceptance criteria:**
- `evaluateState()` returns different actions based on different states
- Low confidence triggers additional data gathering recommendations
- High confidence triggers report generation
- Actions are prioritized and include human-readable reasons

---

### Task 1.2 — Confidence Scoring System

```
STATUS: [x]
LOCK: UNLOCKED
PRIORITY: CRITICAL
DEPENDS ON: nothing
BLOCKS: 1.1 (partially — orchestrator uses confidence), 3.1, 5.1, 5.2, 7.2
```

**What:** Build a unified confidence scoring system that tracks how confident the system is about each psychometric dimension, each career recommendation, and the overall profile.

**Why:** Currently there are no confidence metrics that the system uses to make decisions. The quiz scores have optional `confidence` fields but they're not aggregated or used for anything. Without confidence scoring, the system can't self-correct or decide when it has enough data. The hackathon wants "self-correction" — confidence is the signal that drives self-correction.

**Implementation:**

Create `src/lib/agent/confidence.ts`:
- `computeDimensionConfidence(dimension: string, sources: ConfidenceSource[]): number` — 0-100 score based on: number of evidence sources, agreement between sources, recency of data, diversity of source types (quiz + session + data = higher than quiz alone)
- `computeProfileConfidence(profile: ComputedProfile, insights: DataInsight[], quizScores: QuizScore[], sessionInsights: SessionInsight[]): ConfidenceProfile` — aggregates dimension confidences into overall profile confidence
- `identifyGaps(confidenceProfile: ConfidenceProfile): DimensionGap[]` — returns dimensions with confidence below threshold, ranked by importance
- Confidence formula: `base_score * source_diversity_multiplier * evidence_count_factor * agreement_bonus`
  - `source_diversity_multiplier`: 1 source type = 0.6, 2 types = 0.8, 3+ types = 1.0
  - `evidence_count_factor`: min(evidence_count / 3, 1.0)
  - `agreement_bonus`: +0.1 if all sources agree within 15% range

**Files to create:**
- `src/lib/agent/confidence.ts`

**Files to modify:**
- `src/types/index.ts` — add `ConfidenceProfile`, `ConfidenceSource`, `DimensionGap`

**Acceptance criteria:**
- Dimensions with only quiz data score lower than dimensions with quiz + session + data source evidence
- `identifyGaps()` returns the weakest dimensions first
- Confidence is 0-100 scale, deterministic given same inputs

---

### Task 1.3 — Agent Decision Log Store

```
STATUS: [x]
LOCK: UNLOCKED
PRIORITY: HIGH
DEPENDS ON: 1.1
BLOCKS: 6.1, 6.2
```

**What:** Create a Zustand store and Firestore persistence layer for agent decisions so they can be displayed in the UI and reviewed by judges.

**Why:** The single most powerful way to show judges "this is not a prompt wrapper" is a visible log of autonomous agent reasoning. If judges can see "Agent decided to run Work Values quiz because confidence was 35% — after quiz, confidence rose to 72%", that's undeniable evidence of agentic behavior.

**Implementation:**

Create `src/stores/agent-store.ts`:
- State: `decisions: AgentDecision[]`, `currentPlan: AgentAction[]`, `isEvaluating: boolean`
- Actions: `addDecision()`, `setPlan()`, `markActionComplete()`, `clearLog()`
- Each decision: `{ id, timestamp, action, reason, confidenceBefore, confidenceAfter, outcome }`

Add Firestore helpers in `src/lib/firebase/firestore.ts`:
- `saveAgentDecision(uid: string, decision: AgentDecision)`
- `getAgentDecisions(uid: string): AgentDecision[]`

**Files to create:**
- `src/stores/agent-store.ts`

**Files to modify:**
- `src/lib/firebase/firestore.ts` — add agent decision persistence
- `src/types/index.ts` — add `AgentDecision` type if not already from 1.1

**Acceptance criteria:**
- Decisions persist across page reloads (Firestore backed)
- Store is reactive — UI updates when new decisions are added
- Decision log includes before/after confidence snapshots

---

## Phase 2: Agentic Data Pipeline

> Transform data analysis from "user connects source, we fetch" into "agent analyzes, identifies signals, finds gaps, recommends next sources."

---

### Task 2.1 — Autonomous Data Analysis Agent

```
STATUS: [x]
LOCK: UNLOCKED
PRIORITY: HIGH
DEPENDS ON: 1.1, 1.2
BLOCKS: 2.2, 2.3
```

**What:** After a user connects a data source, instead of just fetching raw data and deferring analysis to the report, run an immediate AI analysis that extracts signals, scores dimension confidence, and logs an agent decision.

**Why:** Currently data routes (gmail, drive, etc.) just fetch raw content and return metadata. The actual analysis is deferred to report generation as a single massive prompt. This is the definition of "prompt wrapper." An agentic system analyzes each source independently, builds running confidence, and uses the results to decide what to do next.

**Implementation:**

Create `src/lib/agent/data-analyzer.ts`:
- `analyzeDataSource(source: DataInsight, existingProfile: ConfidenceProfile): DataAnalysisResult`
- Returns: extracted signals (with dimensions mapped), updated confidence scores, identified themes, recommended next actions
- Uses Gemini 3 Flash with a structured output schema
- The analysis prompt should explicitly ask: "What dimensions does this data strengthen? What dimensions still have no evidence? What additional data sources would help?"

Modify existing data API routes (`/api/data/gmail`, `/api/data/drive`, `/api/data/notion`, `/api/data/chatgpt`, `/api/data/upload`):
- After fetching raw data, call `analyzeDataSource()`
- Store extracted signals in assessment store
- Log agent decision: "Analyzed Gmail — found 4 signals for communication style, 2 for analytical ability. Confidence on Social dimension rose from 20% to 55%."
- Return analysis results alongside raw metadata

**Files to create:**
- `src/lib/agent/data-analyzer.ts`

**Files to modify:**
- `src/app/api/data/gmail/route.ts`
- `src/app/api/data/drive/route.ts`
- `src/app/api/data/notion/route.ts`
- `src/app/api/data/chatgpt/route.ts`
- `src/app/api/data/upload/route.ts`
- `src/lib/gemini/prompts.ts` — add data analysis agent prompt

**Acceptance criteria:**
- Each data source produces dimension-mapped signals immediately after connection
- Confidence profile updates in real time as sources are connected
- Agent decision log shows reasoning for each analysis

---

### Task 2.2 — Gap Detection & Source Recommendation

```
STATUS: [x]
LOCK: UNLOCKED
PRIORITY: MEDIUM
DEPENDS ON: 2.1, 1.2
BLOCKS: 7.1
```

**What:** After each data source is analyzed, the agent evaluates overall confidence and recommends which additional sources would best fill gaps.

**Why:** Instead of the user guessing which sources to connect, the agent says: "Your technical skills are well-evidenced from Drive documents, but I have no data on your communication style. Connecting Gmail would likely strengthen that dimension." This shows autonomous planning and reasoning.

**Implementation:**

Add to `src/lib/agent/orchestrator.ts`:
- `recommendDataSources(gaps: DimensionGap[], connectedSources: string[]): SourceRecommendation[]`
- Maps dimensions to likely data sources: communication → Gmail, technical → Drive/GitHub, interests → Notion/ChatGPT, etc.
- Returns prioritized list of unconnected sources that would most improve confidence

Expose via the `/api/agent/evaluate` endpoint.

**Files to modify:**
- `src/lib/agent/orchestrator.ts`
- `src/app/api/agent/evaluate/route.ts`
- `src/types/index.ts` — add `SourceRecommendation`

**Acceptance criteria:**
- Recommendations change based on which sources are already connected
- Each recommendation includes expected confidence improvement
- Recommendations include human-readable reasoning

---

### Task 2.3 — Cross-Stage Evidence Correlation Agent

```
STATUS: [x]
LOCK: UNLOCKED
PRIORITY: MEDIUM
DEPENDS ON: 2.1
BLOCKS: 5.1
```

**What:** Create an agent that runs after data collection and finds correlations across different sources — patterns that no single source reveals alone.

**Why:** This is the "wow factor" for judges. Finding that "you write longest emails about design (Gmail) + scored 92 on Artistic (quiz) + engagement peaked during creative discussion (session) = high-confidence creative career match with 3-source evidence chain" is something a single prompt can't do well. It requires multi-step reasoning across data types.

**Implementation:**

Create `src/lib/agent/correlator.ts`:
- `correlateEvidence(dataInsights: DataInsight[], quizScores: QuizScore[], sessionInsights: SessionInsight[], signals: UserSignal[]): CorrelatedInsight[]`
- Uses Gemini 3 Pro to find cross-source patterns
- Each insight includes: dimensions affected, all evidence sources, correlation strength, surprise factor (is this expected or a hidden pattern?)
- Specifically looks for: convergent evidence (multiple sources agree), divergent evidence (sources disagree — interesting!), hidden talents (strong signals user doesn't self-report)

Create API route `src/app/api/agent/correlate/route.ts`.

**Files to create:**
- `src/lib/agent/correlator.ts`
- `src/app/api/agent/correlate/route.ts`

**Files to modify:**
- `src/lib/gemini/prompts.ts` — add correlation agent prompt
- `src/types/index.ts` — add `CorrelatedInsight`

**Acceptance criteria:**
- Identifies at least 1 cross-source pattern per user
- Each pattern cites evidence from 2+ different source types
- Includes "surprise factor" rating

---

## Phase 3: Agentic Quiz System

> Transform the quiz from "generate questions → user answers → score" into an agent that adapts in real time, identifies weak dimensions, and autonomously decides when to go deeper.

---

### Task 3.1 — Confidence-Gated Quiz Adaptation

```
STATUS: [x]
LOCK: UNLOCKED
PRIORITY: HIGH
DEPENDS ON: 1.2
BLOCKS: 3.2
```

**What:** After each quiz batch is scored, compute dimension confidence and have the agent decide: generate harder/deeper questions for low-confidence dimensions, skip dimensions with high confidence, or suggest switching modules.

**Why:** Currently quiz adaptation is shallow — previous answers are appended to the next prompt as context. There's no scoring feedback loop. A truly adaptive quiz uses confidence to decide what to ask next, like a real psychometric assessment (Computer Adaptive Testing). This transforms the quiz from "prompt wrapper" to "adaptive agent."

**Implementation:**

Modify `src/app/api/gemini/quiz/route.ts`:
- After receiving quiz batch request, compute current dimension confidence from existing answers
- Pass confidence gaps to the generation prompt: "The user's Investigative dimension confidence is only 25%. Generate questions that specifically probe this dimension."
- Include scoring results from previous questions (not just raw answers) so the model knows what was scored high/low
- Add `adaptationReason` to the response: why these specific questions were chosen

Modify `src/app/api/gemini/quiz-score/route.ts`:
- After scoring, compute updated dimension confidence
- Return `updatedConfidence: Record<string, number>` and `recommendedNextModule: QuizModuleId | null`

**Files to modify:**
- `src/app/api/gemini/quiz/route.ts`
- `src/app/api/gemini/quiz-score/route.ts`
- `src/lib/gemini/prompts.ts` — update quiz generation prompt with confidence-aware instructions

**Acceptance criteria:**
- Questions target low-confidence dimensions specifically
- Response includes why these questions were generated
- Confidence updates after each scoring round

---

### Task 3.2 — Autonomous Module Selection

```
STATUS: [x]
LOCK: UNLOCKED
PRIORITY: MEDIUM
DEPENDS ON: 3.1, 1.1
BLOCKS: nothing
```

**What:** Instead of the user choosing which quiz module to take next, the agent evaluates overall dimension confidence and autonomously recommends the optimal next module.

**Why:** Currently users pick modules manually from a list. An agent that says "Based on your data analysis, I already have strong signals for your interests. But your work values are unknown — let's start with Work Values" shows autonomous planning.

**Implementation:**

Add to `src/lib/agent/orchestrator.ts`:
- `recommendNextModule(confidence: ConfidenceProfile, completedModules: QuizModuleId[]): { module: QuizModuleId, reason: string, expectedImpact: string }`
- Logic: map dimensions to modules, find module that covers the most low-confidence dimensions, skip completed modules

Modify `src/app/(app)/quiz/page.tsx`:
- Show agent recommendation at the top: "I recommend starting with Work Values because..."
- User can still choose manually, but the agent's recommendation is prominent
- Log agent decision when recommendation is made

**Files to modify:**
- `src/lib/agent/orchestrator.ts`
- `src/app/(app)/quiz/page.tsx`

**Acceptance criteria:**
- Module recommendation changes based on connected data and completed modules
- Includes explanation of reasoning
- Agent decision logged

---

## Phase 4: Agentic Live Session

> Transform the live session from "chatbot with passive tool calls" into an agent that actively orchestrates the conversation based on confidence gaps and autonomously decides what to probe.

---

### Task 4.1 — Enhanced Tool Orchestration with Confidence Awareness

```
STATUS: [x]
LOCK: UNLOCKED
PRIORITY: HIGH
DEPENDS ON: 1.1, 1.2
BLOCKS: 4.2
```

**What:** Inject current confidence profile into the live session system prompt so the AI knows which dimensions need probing. Add a new tool `evaluateConfidence` that the model can call mid-conversation to check if it's gathered enough signal.

**Why:** Currently the session AI has no awareness of dimension confidence. It follows a fixed 9-phase script regardless of what data already exists. An agent that says "I see your Artistic confidence is already 85% from quiz + data — let me skip creative questions and focus on your weak Enterprise dimension" is genuinely adaptive.

**Implementation:**

Modify `src/lib/gemini/live-session.ts`:
- Inject confidence profile into session config's system instruction
- Add new tool declaration: `evaluateConfidence` — model calls this to get current dimension confidence scores, letting it dynamically decide what to probe
- Add new tool declaration: `logAgentReasoning` — model calls this to explicitly log WHY it chose to probe a specific topic (visible in agent decision log)
- Update `saveInsight` tool to include dimension mapping: which dimension does this observation strengthen?

Modify `src/lib/gemini/prompts.ts`:
- Update `LIVE_SESSION_SYSTEM_PROMPT` to include confidence-aware instructions:
  - "You have access to the user's current dimension confidence. Focus conversation on low-confidence dimensions."
  - "Before each conversational phase, call evaluateConfidence to check what still needs probing."
  - "Use logAgentReasoning to explain your conversational choices."

**Files to modify:**
- `src/lib/gemini/live-session.ts`
- `src/lib/gemini/prompts.ts`
- `src/hooks/use-live-session.ts` — handle new tool callbacks

**Acceptance criteria:**
- Session AI skips topics where confidence is already high
- `evaluateConfidence` tool is called at least once during conversation
- Agent reasoning is logged and visible
- Insights include dimension mappings

---

### Task 4.2 — Temporal Behavioral Timeline

```
STATUS: [x]
LOCK: UNLOCKED
PRIORITY: HIGH
DEPENDS ON: 4.1
BLOCKS: 6.3
```

**What:** Instead of capturing behavioral observations as isolated snapshots, build a temporal timeline that tracks how behavioral signals change over time during the session.

**Why:** The hackathon explicitly discourages "simple vision analyzers" and wants "spatial-temporal video understanding that recognizes cause and effect." A timeline that shows "engagement peaked at 4:30 during creative discussion, dropped at 7:15 during salary questions → this user is intrinsically motivated, not extrinsically" demonstrates temporal cause-and-effect understanding.

**Implementation:**

Create `src/lib/agent/behavioral-timeline.ts`:
- `BehavioralTimeline` class that accumulates timestamped observations
- `addObservation(insight: SessionInsight)`: adds to timeline
- `computeTrends(): BehavioralTrend[]`: computes rising/falling/stable trends for each behavioral category
- `findCorrelations(): BehavioralCorrelation[]`: finds topic-behavior correlations (e.g., "engagement rises when discussing X")
- `generateNarrative(): string`: produces a natural-language summary of the behavioral arc

Add to session page:
- Visual timeline component showing behavioral signals over time (small sparkline charts)
- Real-time updates as the session progresses

**Files to create:**
- `src/lib/agent/behavioral-timeline.ts`
- `src/components/session/behavioral-timeline.tsx`

**Files to modify:**
- `src/app/(app)/session/page.tsx` — integrate timeline display
- `src/hooks/use-live-session.ts` — feed observations into timeline
- `src/types/index.ts` — add `BehavioralTrend`, `BehavioralCorrelation`

**Acceptance criteria:**
- Timeline shows at least 3 behavioral categories over time
- Trends are computed (rising/falling/stable)
- Topic-behavior correlations are identified
- Visible in session UI during and after conversation

---

## Phase 5: Self-Correcting Report

> Transform report generation from "one massive prompt → JSON" into a multi-step agent loop: generate → critique → identify weaknesses → refine → validate.

---

### Task 5.1 — Generate → Critique → Refine Loop

```
STATUS: [x]
LOCK: UNLOCKED
PRIORITY: CRITICAL
DEPENDS ON: 1.1, 1.2, 2.3
BLOCKS: 5.2
```

**What:** Replace single-shot report generation with a multi-step loop where the agent generates a draft, critiques it for weak evidence and low confidence, then refines specific sections.

**Why:** This is the single most important change for the hackathon. Currently the report is generated by ONE Gemini call — the exact pattern the hackathon calls "if a single prompt can solve it, it is not an application." A generate-critique-refine loop with visible iterations is undeniable evidence of agentic behavior.

**Implementation:**

Create `src/lib/agent/report-agent.ts`:
- `generateReport(state: AgentState): AsyncGenerator<ReportAgentStep>` — a streaming generator that yields each step
- Step 1: **Generate Draft** — call Gemini 3 Pro with all data to produce initial report
- Step 2: **Self-Critique** — call Gemini 3 Flash to evaluate the draft: score each section for evidence quality (0-100), identify claims without evidence, flag low-confidence career matches, check for contradictions between sections
- Step 3: **Identify Refinement Targets** — deterministic logic: any section scoring below 60 evidence quality gets queued for refinement
- Step 4: **Targeted Refinement** — for each weak section, call Gemini 3 Pro with the specific section + all available evidence for that dimension + the critique, asking for an improved version
- Step 5: **Final Validation** — call Gemini 3 Flash to verify the refined report is internally consistent and all evidence chains are valid
- Each step yields: `{ step, description, input_summary, output_summary, confidence_change }`
- Log all steps as agent decisions

Modify `src/app/api/gemini/report/route.ts`:
- Replace single generation call with `generateReport()` agent loop
- Return the final report plus the generation trace (list of steps taken)

**Files to create:**
- `src/lib/agent/report-agent.ts`

**Files to modify:**
- `src/app/api/gemini/report/route.ts`
- `src/lib/gemini/prompts.ts` — add critique prompt and refinement prompt

**Acceptance criteria:**
- Report goes through at least 3 steps (generate, critique, refine)
- Weak sections are identified and improved
- Generation trace is returned alongside the report
- Agent decisions logged for each step

---

### Task 5.2 — Confidence-Gated Report Sections

```
STATUS: [ ]
LOCK: UNLOCKED
PRIORITY: MEDIUM
DEPENDS ON: 5.1, 1.2
BLOCKS: nothing
```

**What:** Each report section gets a confidence gate. If confidence for a dimension is below threshold, the report explicitly says "we need more data" instead of guessing, and the agent recommends specific actions to improve it.

**Why:** Generic career quizzes confidently recommend careers with zero evidence. Lumina's differentiator is epistemic honesty. Showing "Career Match: UX Designer — 82% confidence (3 evidence sources)" vs "Career Match: Data Scientist — 34% confidence (quiz only, consider connecting Google Drive for code samples)" demonstrates the agent's self-awareness.

**Implementation:**

Modify `src/lib/agent/report-agent.ts`:
- During critique step, tag each career recommendation with confidence gate status: `sufficient`, `marginal`, `insufficient`
- For `insufficient` recommendations: include a `dataNeeded` field explaining what additional data would raise confidence
- For `marginal` recommendations: include a `caveats` field

Modify report UI components to display confidence gates visually:
- Green/yellow/red confidence badges on career matches
- "How to improve this recommendation" expandable sections

**Files to modify:**
- `src/lib/agent/report-agent.ts`
- `src/components/report/career-paths.tsx`
- `src/components/report/confidence-meter.tsx`
- `src/types/index.ts` — add `ConfidenceGate` to career recommendation type

**Acceptance criteria:**
- Each career match shows a confidence gate badge
- Low-confidence matches include actionable improvement suggestions
- Visual distinction between high/medium/low confidence recommendations

---

## Phase 6: Agent Decision Log UI

> Make the agent's reasoning visible. This is the "wow factor" for judges.

---

### Task 6.1 — Agent Decision Log Component

```
STATUS: [x]
LOCK: UNLOCKED
PRIORITY: HIGH
DEPENDS ON: 1.3
BLOCKS: 6.2, 6.3
```

**What:** Build a reusable UI component that displays the agent's decision log as a visual timeline of reasoning steps.

**Why:** Judges need to SEE the agent thinking. A sidebar/panel showing "Agent analyzed Gmail → found 4 communication signals → confidence rose 20% → recommended Work Values quiz → quiz completed → confidence sufficient → generating report (step 1 of 5)..." makes the agentic nature undeniable. This is presentation points (10%) and innovation points (30%) combined.

**Implementation:**

Create `src/components/agent/decision-log.tsx`:
- Collapsible sidebar panel (shown on all assessment pages)
- Each decision rendered as a card: icon (based on action type), timestamp, action description, reason, confidence delta (with up/down arrow and color)
- Auto-scrolls to latest decision
- Expandable detail view for each decision
- Animated entry (fade in + slide) for new decisions
- Filter by action type

Create `src/components/agent/confidence-dashboard.tsx`:
- Mini dashboard showing current confidence per dimension
- Color-coded bars (red < 40, yellow 40-70, green > 70)
- Updates in real time as agent makes decisions

**Files to create:**
- `src/components/agent/decision-log.tsx`
- `src/components/agent/confidence-dashboard.tsx`

**Files to modify:**
- None yet — integration happens in 6.3

**Acceptance criteria:**
- Decision log renders dynamically as decisions are made
- Confidence deltas are visually clear (green up arrows, red down arrows)
- Panel is collapsible to not obstruct main content
- Mobile responsive

---

### Task 6.2 — Thought Chain Visualization for Report

```
STATUS: [ ]
LOCK: UNLOCKED
PRIORITY: MEDIUM
DEPENDS ON: 5.1, 6.1
BLOCKS: nothing
```

**What:** On the report page, show a "How I Built This Report" section that visualizes the generate → critique → refine steps as a thought chain.

**Why:** This is the single most impressive thing we can show judges. A visual that says "Step 1: Generated draft (8 sections) → Step 2: Self-critique found 3 weak sections → Step 3: Refined Career Match #2 (evidence quality 45% → 78%) → Step 4: Refined Hidden Talents (added 2 new evidence chains) → Step 5: Final validation passed" proves this is not a prompt wrapper.

**Implementation:**

Create `src/components/report/thought-chain.tsx`:
- Vertical stepper/timeline showing each report generation step
- Each step: title, description, confidence change, time taken
- Expandable detail showing what was critiqued and what was improved
- Visual diff for refined sections (before/after)

**Files to create:**
- `src/components/report/thought-chain.tsx`

**Files to modify:**
- `src/app/(app)/report/page.tsx` — add thought chain section

**Acceptance criteria:**
- Shows at least 3 steps in the generation process
- Each step includes confidence metrics
- Expandable detail for each step
- Visually compelling (this is for judges)

---

### Task 6.3 — Integration Across All Pages

```
STATUS: [x]
LOCK: UNLOCKED
PRIORITY: MEDIUM
DEPENDS ON: 6.1, 4.2
BLOCKS: nothing
```

**What:** Integrate the agent decision log and confidence dashboard into all assessment pages: connections, quiz, session, report, and dashboard.

**Why:** The agent should feel omnipresent — always visible, always reasoning. Every page should show what the agent is thinking and how confident it is. This creates the impression of a cohesive agent, not disconnected prompt calls.

**Implementation:**

Modify layout for assessment pages to include a collapsible agent panel:
- `src/app/(app)/connections/page.tsx` — show decisions as sources are connected
- `src/app/(app)/quiz/page.tsx` — show adaptive decisions and module recommendations
- `src/app/(app)/session/page.tsx` — show live decisions + behavioral timeline
- `src/app/(app)/report/page.tsx` — show thought chain + generation decisions
- `src/app/(app)/dashboard/page.tsx` — show full decision history + overall confidence

**Files to modify:**
- `src/app/(app)/connections/page.tsx`
- `src/app/(app)/quiz/page.tsx`
- `src/app/(app)/session/page.tsx`
- `src/app/(app)/report/page.tsx`
- `src/app/(app)/dashboard/page.tsx`

**Acceptance criteria:**
- Agent panel visible on all 5 assessment pages
- Decisions from all stages appear in unified log
- Confidence dashboard reflects current state on every page
- Panel doesn't break mobile layout

---

## Phase 7: Dashboard & Flow Transformation

> Transform the user experience from "click through linear steps" to "the agent guides you."

---

### Task 7.1 — Agent-Driven Dashboard

```
STATUS: [x]
LOCK: UNLOCKED
PRIORITY: HIGH
DEPENDS ON: 1.1, 2.2
BLOCKS: nothing
```

**What:** Replace the current linear stage display on the dashboard with an agent-driven view that shows recommended next actions, current confidence, and why.

**Why:** The dashboard is the first thing judges will see after onboarding. If it shows "Step 1: Connections ✓, Step 2: Quiz, Step 3: Session, Step 4: Report" it looks like a linear wizard. If it shows "Your agent recommends: Connect Gmail (expected +25% communication confidence) → then take Work Values quiz (strongest gap)" it looks like an autonomous system.

**Implementation:**

Modify `src/components/dashboard/pre-completion-dashboard.tsx`:
- Replace linear stage list with agent recommendation cards
- Each card: recommended action, reason, expected confidence impact, "Do This" button
- Current overall confidence display at the top
- "What your agent has learned so far" summary section
- Timeline of past agent decisions (collapsed by default)

**Files to modify:**
- `src/components/dashboard/pre-completion-dashboard.tsx`
- `src/app/(app)/dashboard/page.tsx`

**Acceptance criteria:**
- Dashboard shows agent recommendations, not just stage checkboxes
- Recommendations include reasoning
- Overall confidence is prominently displayed
- Past decisions are accessible

---

### Task 7.2 — Confidence-Gated Stage Transitions

```
STATUS: [x]
LOCK: UNLOCKED
PRIORITY: MEDIUM
DEPENDS ON: 1.1, 1.2
BLOCKS: nothing
```

**What:** Instead of the user manually deciding when to move from quiz to session to report, the agent signals when confidence is sufficient to proceed — or recommends additional work before moving on.

**Why:** A user-driven "Next Step" button is not agentic. An agent that says "Your profile confidence is 68% — sufficient to generate a report, but I recommend one more quiz module (Work Values) to strengthen your career matches. Proceed anyway or take the quiz?" — that's autonomous with human-in-the-loop.

**Implementation:**

Create `src/components/agent/stage-gate.tsx`:
- Component that wraps stage transition buttons
- Shows current confidence and minimum threshold
- If confidence >= threshold: green "Ready to proceed" with "Recommended by your agent"
- If confidence < threshold: yellow "Agent recommends additional work" with specific suggestions, but still allows user to proceed
- Confidence bar visualization

Modify assessment store:
- `canAdvance(stage: AssessmentStage): { ready: boolean, confidence: number, recommendations: string[] }`

**Files to create:**
- `src/components/agent/stage-gate.tsx`

**Files to modify:**
- `src/stores/assessment-store.ts` — add `canAdvance()` method
- `src/app/(app)/quiz/page.tsx` — use stage gate for session transition
- `src/app/(app)/session/page.tsx` — use stage gate for report transition

**Acceptance criteria:**
- Stage transitions show confidence status
- Agent recommendations appear when confidence is low
- User can still override and proceed
- Transitions are logged as agent decisions

---

## Phase 8: Submission Update

> Update all hackathon materials to reflect the agentic architecture.

---

### Task 8.1 — Update Devpost Submission

```
STATUS: [ ]
LOCK: UNLOCKED
PRIORITY: HIGH
DEPENDS ON: all implementation tasks
BLOCKS: nothing
```

**What:** Rewrite `DEVPOST_SUBMISSION.md` to reflect the agentic transformation. Reframe from "multimodal talent discovery platform" to "autonomous career intelligence agent."

**Why:** The submission text is 10% of judging (presentation) but influences how judges perceive the other 90%. The right framing makes judges look for the agentic features.

**Key reframing:**
- Title: "Lumina — Autonomous Career Intelligence Agent"
- Lead with the agent orchestrator, not the features
- "What it does" should describe the agent loop, not the user flow
- "How we built it" should emphasize the multi-agent architecture
- Gemini 3 description should emphasize orchestration across models, not just "we use Flash for X and Pro for Y"
- Include a sentence about self-correcting report generation
- Include a sentence about confidence-gated decision making

**Files to modify:**
- `DEVPOST_SUBMISSION.md`

**Acceptance criteria:**
- No mention of "prompt", "chatbot", "quiz app", or "personality analysis"
- Agent orchestrator is the first thing described
- Self-correction is prominently featured
- Confidence-driven decision making is highlighted

---

### Task 8.2 — Architecture Diagram

```
STATUS: [ ]
LOCK: UNLOCKED
PRIORITY: LOW
DEPENDS ON: all implementation tasks
BLOCKS: nothing
```

**What:** Create a visual architecture diagram showing the agent loop (not a linear pipeline) for the Devpost submission and demo video.

**Why:** A diagram showing decision nodes, confidence gates, feedback loops, and multi-model routing is worth a thousand words for judges evaluating technical execution (40%).

**Deliverable:** A clean diagram (can be ASCII or a design tool export) showing:
- Agent orchestrator at the center
- Data sources feeding in
- Confidence gates between stages
- Self-correction loops on report generation
- Tool calling during live session
- Multi-model routing (Flash/Pro/Live)

**Acceptance criteria:**
- Diagram shows loops, not linear flow
- Confidence gates are visible
- Multi-model routing is clear

---

## Implementation Order (Recommended)

```
Week 1 (Foundation):
  1.2 Confidence Scoring    ←── start here, no dependencies
  1.1 Agent Orchestrator     ←── depends on 1.2
  1.3 Agent Decision Log     ←── depends on 1.1

Week 1-2 (Core Agentic Features):
  5.1 Report Agent Loop      ←── highest impact, depends on 1.1 + 1.2
  4.1 Session Tool Enhancement ←── depends on 1.1 + 1.2
  3.1 Quiz Adaptation        ←── depends on 1.2

Week 2 (Data & UI):
  2.1 Data Analysis Agent    ←── depends on 1.1 + 1.2
  6.1 Decision Log UI        ←── depends on 1.3
  4.2 Behavioral Timeline    ←── depends on 4.1

Week 2-3 (Integration & Polish):
  6.3 Integration Across Pages
  7.1 Agent Dashboard
  7.2 Stage Gates
  2.2 Gap Detection
  2.3 Evidence Correlation
  3.2 Module Selection
  5.2 Confidence-Gated Sections
  6.2 Thought Chain Visualization

Week 3 (Submission):
  8.1 Devpost Update
  8.2 Architecture Diagram
```

---

## Quick Reference — All New Files

```
src/lib/agent/
├── orchestrator.ts          (Task 1.1)
├── types.ts                 (Task 1.1)
├── confidence.ts            (Task 1.2)
├── data-analyzer.ts         (Task 2.1)
├── correlator.ts            (Task 2.3)
├── behavioral-timeline.ts   (Task 4.2)
└── report-agent.ts          (Task 5.1)

src/stores/
└── agent-store.ts           (Task 1.3)

src/app/api/agent/
├── evaluate/route.ts        (Task 1.1)
└── correlate/route.ts       (Task 2.3)

src/components/agent/
├── decision-log.tsx          (Task 6.1)
├── confidence-dashboard.tsx  (Task 6.1)
└── stage-gate.tsx            (Task 7.2)

src/components/session/
└── behavioral-timeline.tsx   (Task 4.2)

src/components/report/
└── thought-chain.tsx         (Task 6.2)
```
